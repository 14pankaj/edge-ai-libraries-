global: 
  egai_vllm_pvc:
    size: 20Gi
  egai_ovms_embed_pvc:
    size: 20Gi
  keeppvc: false # true to persist downloaded models across multiple deployments

Chatqna:
  env:
    ENDPOINT_URL: http://vllm-service

tgiService:
  name: text-generation-service
  enabled: false
vllmService:
  name: vllm-service
  enabled: true
  service:
    port: 8080
ovmsService:
  name: ovmsService
  enabled: false

